{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解線性回歸的模型發展歷程，並了解優勢與劣勢，以及其使用情境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請閱讀以下相關文獻，並回答以下問題\n",
    "\n",
    "[Linear Regression 詳細介紹](https://brohrer.mcknote.com/zh-Hant/how_machine_learning_works/how_linear_regression_works.html)\n",
    "\n",
    "[Logistics Regression 詳細介紹](https://medium.com/@yehjames/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-3%E8%AC%9B-%E7%B7%9A%E6%80%A7%E5%88%86%E9%A1%9E-%E9%82%8F%E8%BC%AF%E6%96%AF%E5%9B%9E%E6%AD%B8-logistic-regression-%E4%BB%8B%E7%B4%B9-a1a5f47017e5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 線性回歸模型能夠準確預測非線性關係的資料集嗎?\n",
    "2. 回歸模型是否對資料分布有基本假設?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.線性回歸模型能夠準確預測非線性關係的資料集嗎?  \n",
    "Ans: 可以。譬如透過特徵工程處理產生新特徵的手法，新的特徵則繼續透過線性回歸找尋適當的模型參數。  \n",
    "產生非線性新特徵方法: \n",
    "透過多項式重新組合或提高特徵的維度: 特徵自己次方提升(X1\\*\\*2) 或是 X1 \\* X2..等延伸\n",
    "\n",
    "2.回歸模型是否對資料分布有基本假設?  \n",
    "Ans:單純線性回歸沒有基本假設。 邏輯回歸模型則是基於白努力分佈的假設前提建立機率模型，求最大似然。(目標函數則是將最大似然取-Log求最小Loss，並透過Gradient Descent的方式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
