{"cells":[{"metadata":{},"cell_type":"markdown","source":"## [CS231n](http://cs231n.github.io/convolutional-networks/)\n**Local Connectivity.** When dealing with high-dimensional inputs such as images, as we saw above it is impractical to connect neurons to all neurons in the previous volume. Instead, we will connect each neuron to only a local region of the input volume. The spatial extent of this connectivity is a hyperparameter called the receptive field of the neuron (equivalently this is the filter size). The extent of the connectivity along the depth axis is always equal to the depth of the input volume. It is important to emphasize again this asymmetry in how we treat the spatial dimensions (width and height) and the depth dimension: The connections are local in space (along width and height), but always full along the entire depth of the input volume.\n\n`Example 1.` For example, suppose that the input volume has size [32x32x3], (e.g. an RGB CIFAR-10 image). If the receptive field (or the filter size) is 5x5, then each neuron in the Conv Layer will have weights to a [5x5x3] region in the input volume, for a total of 5*5*3 = 75 weights (and +1 bias parameter). Notice that the extent of the connectivity along the depth axis must be 3, since this is the depth of the input volume.\n\n`Example 2.` Suppose an input volume had size [16x16x20]. Then using an example receptive field size of 3x3, every neuron in the Conv Layer would now have a total of 3*3*20 = 180 connections to the input volume. Notice that, again, the connectivity is local in space (e.g. 3x3), but full along the input depth (20).\n\nWe can compute the spatial size of the output volume as a function of the input volume size (W), the receptive field size of the Conv Layer neurons (F), the stride with which they are applied (S), and the amount of zero padding used (P) on the border. You can convince yourself that the correct formula for calculating how many neurons “fit” is given by (W−F+2P)/S+1. For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output.\n\n# $ W' = \\frac{W−F+2P}{S} +1$"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def single_conv(feature_map, kernel, bias=0, stride=1):\n    if kernel.shape[:2] != bias.shape:\n        print('Kernel size and bias size are not same')\n        return None\n    #if feature_map.shape[-1] != kernel.shape[-1]:\n    #    print('Kernel depth and feature depth are not same')\n    #    return None\n    #new feature size or steps for convolution\n    h_step = (feature_map.shape[1] -  kernel.shape[1]) // stride + 1\n    v_step = (feature_map.shape[0] - kernel.shape[0]) // stride + 1\n    print(h_step, v_step)\n    new_feature = np.zeros((v_step, h_step), dtype=feature_map.dtype)\n    for v in range(0, v_step):\n        for h in range(0, h_step):\n            # inner product\n            print('(v, h):({}, {})'.format(v, h))\n            print('f:\\n', feature_map[v:v+kernel.shape[1], h:h+kernel.shape[0]])\n            print('k:\\n', kernel)\n            print('dot:\\n', feature_map[v:v+kernel.shape[1], h:h+kernel.shape[0]] * kernel)\n            print('b:\\n', bias)\n            print('tmp_result', feature_map[v:v+kernel.shape[1], h:h+kernel.shape[0]] * kernel + bias)\n            print('sum:', np.sum(np.sum(feature_map[v:v+kernel.shape[1], h:h+kernel.shape[0]] * kernel + bias, axis=0), axis=0))\n            new_feature[v, h] = np.sum(np.sum(feature_map[v:v+kernel.shape[1], h:h+kernel.shape[0]] * kernel + bias, axis=0), axis=0)\n            print('result:', new_feature[v, h])\n            # relu activation\n            new_feature[v, h] = np.max(new_feature[v, h], 0) \n    return new_feature        ","execution_count":78,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_feature = np.array([[1, 1, 1, 1, 1, 1, 1],\n                          [2, 2, 2, 2, 2, 2, 2],\n                          [1, 1, 1, 1, 1, 1, 1],\n                          [3, 3, 3, 3, 3, 3, 3],\n                          [1, 1, 1, 1, 1, 1, 1],\n                          [4, 4, 4, 4, 4, 4, 4],\n                          [1, 1, 1, 1, 1, 1, 1],\n                         ])\nkernel = np.array([[0, 0, 0],\n                   [1, 1, 1],\n                   [0, 0, 0]\n                  ])\nbias = np.zeros(kernel.shape).astype(input_feature.dtype)\n\nnew_feature = single_conv(input_feature, kernel, bias)","execution_count":79,"outputs":[{"output_type":"stream","text":"5 5\n(v, h):(0, 0)\nf:\n [[1 1 1]\n [2 2 2]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [2 2 2]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [2 2 2]\n [0 0 0]]\nsum: 6\nresult: 6\n(v, h):(0, 1)\nf:\n [[1 1 1]\n [2 2 2]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [2 2 2]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [2 2 2]\n [0 0 0]]\nsum: 6\nresult: 6\n(v, h):(0, 2)\nf:\n [[1 1 1]\n [2 2 2]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [2 2 2]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [2 2 2]\n [0 0 0]]\nsum: 6\nresult: 6\n(v, h):(0, 3)\nf:\n [[1 1 1]\n [2 2 2]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [2 2 2]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [2 2 2]\n [0 0 0]]\nsum: 6\nresult: 6\n(v, h):(0, 4)\nf:\n [[1 1 1]\n [2 2 2]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [2 2 2]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [2 2 2]\n [0 0 0]]\nsum: 6\nresult: 6\n(v, h):(1, 0)\nf:\n [[2 2 2]\n [1 1 1]\n [3 3 3]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(1, 1)\nf:\n [[2 2 2]\n [1 1 1]\n [3 3 3]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(1, 2)\nf:\n [[2 2 2]\n [1 1 1]\n [3 3 3]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(1, 3)\nf:\n [[2 2 2]\n [1 1 1]\n [3 3 3]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(1, 4)\nf:\n [[2 2 2]\n [1 1 1]\n [3 3 3]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(2, 0)\nf:\n [[1 1 1]\n [3 3 3]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [3 3 3]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [3 3 3]\n [0 0 0]]\nsum: 9\nresult: 9\n(v, h):(2, 1)\nf:\n [[1 1 1]\n [3 3 3]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [3 3 3]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [3 3 3]\n [0 0 0]]\nsum: 9\nresult: 9\n(v, h):(2, 2)\nf:\n [[1 1 1]\n [3 3 3]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [3 3 3]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [3 3 3]\n [0 0 0]]\nsum: 9\nresult: 9\n(v, h):(2, 3)\nf:\n [[1 1 1]\n [3 3 3]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [3 3 3]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [3 3 3]\n [0 0 0]]\nsum: 9\nresult: 9\n(v, h):(2, 4)\nf:\n [[1 1 1]\n [3 3 3]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [3 3 3]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [3 3 3]\n [0 0 0]]\nsum: 9\nresult: 9\n(v, h):(3, 0)\nf:\n [[3 3 3]\n [1 1 1]\n [4 4 4]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(3, 1)\nf:\n [[3 3 3]\n [1 1 1]\n [4 4 4]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(3, 2)\nf:\n [[3 3 3]\n [1 1 1]\n [4 4 4]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(3, 3)\nf:\n [[3 3 3]\n [1 1 1]\n [4 4 4]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(3, 4)\nf:\n [[3 3 3]\n [1 1 1]\n [4 4 4]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [1 1 1]\n [0 0 0]]\nsum: 3\nresult: 3\n(v, h):(4, 0)\nf:\n [[1 1 1]\n [4 4 4]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [4 4 4]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [4 4 4]\n [0 0 0]]\nsum: 12\nresult: 12\n(v, h):(4, 1)\nf:\n [[1 1 1]\n [4 4 4]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [4 4 4]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [4 4 4]\n [0 0 0]]\nsum: 12\nresult: 12\n(v, h):(4, 2)\nf:\n [[1 1 1]\n [4 4 4]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [4 4 4]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [4 4 4]\n [0 0 0]]\nsum: 12\nresult: 12\n(v, h):(4, 3)\nf:\n [[1 1 1]\n [4 4 4]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [4 4 4]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [4 4 4]\n [0 0 0]]\nsum: 12\nresult: 12\n(v, h):(4, 4)\nf:\n [[1 1 1]\n [4 4 4]\n [1 1 1]]\nk:\n [[0 0 0]\n [1 1 1]\n [0 0 0]]\ndot:\n [[0 0 0]\n [4 4 4]\n [0 0 0]]\nb:\n [[0 0 0]\n [0 0 0]\n [0 0 0]]\ntmp_result [[0 0 0]\n [4 4 4]\n [0 0 0]]\nsum: 12\nresult: 12\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_feature","execution_count":80,"outputs":[{"output_type":"execute_result","execution_count":80,"data":{"text/plain":"array([[ 6,  6,  6,  6,  6],\n       [ 3,  3,  3,  3,  3],\n       [ 9,  9,  9,  9,  9],\n       [ 3,  3,  3,  3,  3],\n       [12, 12, 12, 12, 12]])"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}