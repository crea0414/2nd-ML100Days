{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning (Resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Dense, Conv2D, Activation, BatchNormalization, Flatten, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageFile\n",
    "from math import ceil\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "import copy\n",
    "import json\n",
    "%matplotlib inline\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 32, 32, 3) (35000, 1) (15000, 32, 32, 3) (15000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train,stratify=y_train, test_size=0.3, random_state=2019)\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 32, 32, 3) (35000, 10) (15000, 32, 32, 3) (15000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "num_cls = 10\n",
    "y_train = to_categorical(y_train, num_cls)\n",
    "y_valid = to_categorical(y_valid, num_cls)\n",
    "y_test  = to_categorical(y_test,  num_cls)\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['file_path', 'label']\n",
    "train_df, valid_df = pd.DataFrame(), pd.DataFrame()\n",
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(img_set, label_set, new_shape=(224, 224),\n",
    "            dst_dir='/train_imgs', filename='train_id'):\n",
    "    df = pd.DataFrame(columns=['file_path', 'label'])\n",
    "    if not os.path.exists(dst_dir):\n",
    "            os.makedirs(dst_dir)\n",
    "    for i in tqdm(range(len(img_set))):\n",
    "        tmp_label =  label_set[i].argmax()\n",
    "        if not os.path.exists(dst_dir +'/'+ str(tmp_label)):\n",
    "            os.makedirs(dst_dir +'/'+ str(tmp_label))\n",
    "        \n",
    "        dst_file = dst_dir+'/'+str(tmp_label)+'/'+filename+'_'+str(i)+'_'+str(tmp_label) +'.jpeg'\n",
    "        #print(dst_file)\n",
    "        \n",
    "        df.loc[i, 'file_path'] = dst_file\n",
    "        df.loc[i, 'label'] = str(tmp_label)\n",
    "        tmp = cv2.resize(img_set[i], new_shape)\n",
    "        tmp = cv2.cvtColor(tmp, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(dst_file, tmp)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aeb48ba9b75411a9963e66283aefa2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a210a6ce303b45bf996a22bcee60c702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635ece16b46b488096d3cf1f1812035e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = utility(x_train, y_train, dst_dir='/home/crea/tf_env/train_imgs', filename='train_id')\n",
    "valid_df = utility(x_valid, y_valid, dst_dir='/home/crea/tf_env/valid_imgs', filename='valid_id')\n",
    "test_df   = utility(x_test, y_test, dst_dir='/home/crea/tf_env/test_imgs', filename='test_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('cifar10_df.csv', encoding='utf-8')\n",
    "valid_df.to_csv('cifar10_df.csv', encoding='utf-8')\n",
    "test_df.to_csv('cifar10_df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                       file_path label\n",
       " 0  /home/crea/tf_env/test_imgs/3/test_id_0_3.png     3\n",
       " 1  /home/crea/tf_env/test_imgs/8/test_id_1_8.png     8\n",
       " 2  /home/crea/tf_env/test_imgs/8/test_id_2_8.png     8\n",
       " 3  /home/crea/tf_env/test_imgs/0/test_id_3_0.png     0\n",
       " 4  /home/crea/tf_env/test_imgs/6/test_id_4_6.png     6,\n",
       "                                          file_path label\n",
       " 0  /home/crea/tf_env/train_imgs/1/train_id_0_1.png     1\n",
       " 1  /home/crea/tf_env/train_imgs/8/train_id_1_8.png     8\n",
       " 2  /home/crea/tf_env/train_imgs/6/train_id_2_6.png     6\n",
       " 3  /home/crea/tf_env/train_imgs/6/train_id_3_6.png     6\n",
       " 4  /home/crea/tf_env/train_imgs/0/train_id_4_0.png     0,\n",
       "                                          file_path label\n",
       " 0  /home/crea/tf_env/valid_imgs/2/valid_id_0_2.png     2\n",
       " 1  /home/crea/tf_env/valid_imgs/2/valid_id_1_2.png     2\n",
       " 2  /home/crea/tf_env/valid_imgs/5/valid_id_2_5.png     5\n",
       " 3  /home/crea/tf_env/valid_imgs/2/valid_id_3_2.png     2\n",
       " 4  /home/crea/tf_env/valid_imgs/2/valid_id_4_2.png     2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(), train_df.head(), valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2570        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,772,746\n",
      "Trainable params: 1,184,010\n",
      "Non-trainable params: 23,588,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "\n",
    "K.clear_session()\n",
    "#using resnet50 imagenet pretrained model\n",
    "resnet50_model = ResNet50(input_shape=(256, 256, 3), weights='imagenet', pooling='avg', include_top=False)\n",
    "\n",
    "#fix pretrained parameter\n",
    "for layer in resnet50_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# new classifier\n",
    "last_feature_map = resnet50_model.output\n",
    "x = Dense(512, activation='relu')(last_feature_map)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output_layer = Dense(num_cls, activation='softmax')(x)\n",
    "model = Model(inputs=[resnet50_model.input], outputs=[output_layer])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(#featurewise_center=True,\n",
    "                                     #featurewise_std_normalization=True,\n",
    "                                     #samplewise_center=True,\n",
    "                                     #samplewise_std_normalization=True,\n",
    "                                     #rescale= 1/255.,\n",
    "                                     preprocessing_function=preprocess_input,\n",
    "                                     rotation_range=20,\n",
    "                                     width_shift_range= 0.2,\n",
    "                                     height_shift_range= 0.2,\n",
    "                                     data_format='channels_last'\n",
    "                                     )\n",
    "test_generator = ImageDataGenerator(\n",
    "                                    #featurewise_center=True,\n",
    "                                    #featurewise_std_normalization=True,\n",
    "                                    #samplewise_center=True,\n",
    "                                    #samplewise_std_normalization=True\n",
    "                                    #rescale= 1/255.,\n",
    "                                    preprocessing_function=preprocess_input,\n",
    "                                    data_format='channels_last'\n",
    "                                    )\n",
    "#train_generator.fit(x_train)\n",
    "#test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35000 images belonging to 10 classes.\n",
      "Found 15000 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 2.0401 - acc: 0.3203 - val_loss: 1.9738 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.97384, saving model to cifar10.h5\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 1.3711 - acc: 0.5240 - val_loss: 1.4752 - val_acc: 0.5494\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.97384 to 1.47522, saving model to cifar10.h5\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 352s 252ms/step - loss: 1.1878 - acc: 0.5889 - val_loss: 1.3397 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.47522 to 1.33966, saving model to cifar10.h5\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 1.1067 - acc: 0.6177 - val_loss: 1.1840 - val_acc: 0.6449\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.33966 to 1.18401, saving model to cifar10.h5\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 1.0423 - acc: 0.6413 - val_loss: 1.2096 - val_acc: 0.6463\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.18401\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 351s 250ms/step - loss: 0.9918 - acc: 0.6606 - val_loss: 1.1517 - val_acc: 0.6653\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.18401 to 1.15175, saving model to cifar10.h5\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.9486 - acc: 0.6705 - val_loss: 1.0686 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.15175 to 1.06860, saving model to cifar10.h5\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 354s 253ms/step - loss: 0.9209 - acc: 0.6811 - val_loss: 1.0736 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.06860\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.9010 - acc: 0.6884 - val_loss: 1.0268 - val_acc: 0.7064\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.06860 to 1.02681, saving model to cifar10.h5\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.8920 - acc: 0.6953 - val_loss: 1.0479 - val_acc: 0.7028\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.02681\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.8682 - acc: 0.7009 - val_loss: 0.9831 - val_acc: 0.7193\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.02681 to 0.98307, saving model to cifar10.h5\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 349s 250ms/step - loss: 0.8474 - acc: 0.7054 - val_loss: 0.9175 - val_acc: 0.7337\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.98307 to 0.91747, saving model to cifar10.h5\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.8437 - acc: 0.7082 - val_loss: 0.8895 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.91747 to 0.88950, saving model to cifar10.h5\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.8271 - acc: 0.7140 - val_loss: 0.8557 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.88950 to 0.85568, saving model to cifar10.h5\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.8193 - acc: 0.7170 - val_loss: 0.8520 - val_acc: 0.7497\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.85568 to 0.85198, saving model to cifar10.h5\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.7999 - acc: 0.7233 - val_loss: 0.8247 - val_acc: 0.7568\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.85198 to 0.82473, saving model to cifar10.h5\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.7915 - acc: 0.7219 - val_loss: 0.7986 - val_acc: 0.7618\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.82473 to 0.79863, saving model to cifar10.h5\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.7908 - acc: 0.7259 - val_loss: 0.7750 - val_acc: 0.7692\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.79863 to 0.77504, saving model to cifar10.h5\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.7787 - acc: 0.7291 - val_loss: 0.7451 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.77504 to 0.74515, saving model to cifar10.h5\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.7735 - acc: 0.7294 - val_loss: 0.7442 - val_acc: 0.7776\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.74515 to 0.74415, saving model to cifar10.h5\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.7628 - acc: 0.7351 - val_loss: 0.7621 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.74415\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.7600 - acc: 0.7339 - val_loss: 0.7537 - val_acc: 0.7747\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.74415\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.7555 - acc: 0.7389 - val_loss: 0.7462 - val_acc: 0.7764\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.74415\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.7484 - acc: 0.7380 - val_loss: 0.7265 - val_acc: 0.7810\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.74415 to 0.72651, saving model to cifar10.h5\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.7383 - acc: 0.7431 - val_loss: 0.7120 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.72651 to 0.71197, saving model to cifar10.h5\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.7375 - acc: 0.7413 - val_loss: 0.6982 - val_acc: 0.7859\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.71197 to 0.69823, saving model to cifar10.h5\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 351s 250ms/step - loss: 0.7242 - acc: 0.7472 - val_loss: 0.7236 - val_acc: 0.7807\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.69823\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.7264 - acc: 0.7466 - val_loss: 0.6903 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.69823 to 0.69026, saving model to cifar10.h5\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.7274 - acc: 0.7476 - val_loss: 0.7128 - val_acc: 0.7845\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.69026\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.7226 - acc: 0.7499 - val_loss: 0.7011 - val_acc: 0.7873\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.69026\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.7186 - acc: 0.7485 - val_loss: 0.7031 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.69026\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 352s 252ms/step - loss: 0.7113 - acc: 0.7533 - val_loss: 0.7034 - val_acc: 0.7867\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.69026\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 349s 250ms/step - loss: 0.7097 - acc: 0.7529 - val_loss: 0.6738 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.69026 to 0.67377, saving model to cifar10.h5\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 349s 250ms/step - loss: 0.7070 - acc: 0.7558 - val_loss: 0.6472 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.67377 to 0.64716, saving model to cifar10.h5\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.7065 - acc: 0.7534 - val_loss: 0.6428 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.64716 to 0.64284, saving model to cifar10.h5\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.6929 - acc: 0.7565 - val_loss: 0.6613 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.64284\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.6988 - acc: 0.7547 - val_loss: 0.6613 - val_acc: 0.7975\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.64284\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 348s 249ms/step - loss: 0.6904 - acc: 0.7611 - val_loss: 0.6525 - val_acc: 0.7999\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.64284\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.6882 - acc: 0.7598 - val_loss: 0.6334 - val_acc: 0.8045\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.64284 to 0.63344, saving model to cifar10.h5\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 349s 250ms/step - loss: 0.6841 - acc: 0.7616 - val_loss: 0.6551 - val_acc: 0.7990\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.63344\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.6728 - acc: 0.7648 - val_loss: 0.6434 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.63344\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 347s 248ms/step - loss: 0.6770 - acc: 0.7641 - val_loss: 0.6183 - val_acc: 0.8089\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.63344 to 0.61827, saving model to cifar10.h5\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 348s 249ms/step - loss: 0.6725 - acc: 0.7644 - val_loss: 0.6204 - val_acc: 0.8063\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.61827\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 345s 247ms/step - loss: 0.6664 - acc: 0.7655 - val_loss: 0.6460 - val_acc: 0.7995\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.61827\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 349s 250ms/step - loss: 0.6615 - acc: 0.7668 - val_loss: 0.6349 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.61827\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.6615 - acc: 0.7699 - val_loss: 0.6395 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.61827\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.6720 - acc: 0.7684 - val_loss: 0.6167 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.61827 to 0.61672, saving model to cifar10.h5\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.6635 - acc: 0.7668 - val_loss: 0.6109 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.61672 to 0.61090, saving model to cifar10.h5\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 347s 248ms/step - loss: 0.6589 - acc: 0.7693 - val_loss: 0.6214 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.61090\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.6507 - acc: 0.7725 - val_loss: 0.6148 - val_acc: 0.8093\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.61090\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.6513 - acc: 0.7726 - val_loss: 0.6021 - val_acc: 0.8135\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.61090 to 0.60206, saving model to cifar10.h5\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.6473 - acc: 0.7743 - val_loss: 0.6092 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.60206\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.6441 - acc: 0.7757 - val_loss: 0.6382 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.60206\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.6364 - acc: 0.7774 - val_loss: 0.6205 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.60206\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 351s 251ms/step - loss: 0.6474 - acc: 0.7741 - val_loss: 0.6236 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.60206\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 349s 249ms/step - loss: 0.6454 - acc: 0.7745 - val_loss: 0.6177 - val_acc: 0.8095\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.60206\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.6354 - acc: 0.7768 - val_loss: 0.6267 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.60206\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 348s 249ms/step - loss: 0.6422 - acc: 0.7762 - val_loss: 0.6199 - val_acc: 0.8091\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.60206\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 350s 250ms/step - loss: 0.6324 - acc: 0.7787 - val_loss: 0.6246 - val_acc: 0.8079\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.60206\n",
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 352s 252ms/step - loss: 0.6415 - acc: 0.7766 - val_loss: 0.6153 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.60206\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 346s 247ms/step - loss: 0.6321 - acc: 0.7793 - val_loss: 0.6205 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.60206\n",
      "Epoch 00061: early stopping\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 25\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-5\n",
    "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.1, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "checkpoint = ModelCheckpoint(monitor='val_loss', filepath='cifar10.h5', \n",
    "                             save_best_only=True, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator.flow_from_directory('/home/crea/tf_env/train_imgs', \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                      \n",
    "                              epochs=EPOCHS, steps_per_epoch=ceil(len(x_train)/BATCH_SIZE),\n",
    "                              validation_data= test_generator.flow_from_directory('/home/crea/tf_env/valid_imgs',\n",
    "                                                                   batch_size=BATCH_SIZE),\n",
    "                              validation_steps=ceil(len(x_valid)/BATCH_SIZE),\n",
    "                              verbose=1, callbacks=[lr_reducer, early_stop, checkpoint],\n",
    "                              shuffle=True)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "[0.6202231776714325, 0.8083999997377396]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fd101846ba8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('cifar10.h5')\n",
    "BATCH_SIZE = 100\n",
    "score = model.evaluate_generator(test_generator.flow_from_directory('/home/crea/tf_env/test_imgs', \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                                  ceil(len(x_test)/BATCH_SIZE),\n",
    "                    \n",
    "                        )\n",
    "print(score)\n",
    "\n",
    "#for k in ['val_acc', 'loss', 'val_loss', 'acc']:\n",
    "#    with open('history_'+k+'.json', 'w') as f:\n",
    "#        json.dump(history.history[k], f)\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "plt.hlines(score[0], 0, len(history.history['loss']), linestyle='--', color='r')\n",
    "history_df[['acc', 'val_acc']].plot()\n",
    "plt.hlines(score[1], 0, len(history.history['acc']), linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8fcc191b38>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8fcc191cc0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8fcc191dd8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8fcc191e10>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8fcc191f98>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8fcc188fd0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8fcc195128>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8fcc1952b0>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8fcc1953c8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8fcc195400>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8fcc195438>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8fcc1955c0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8fcc1956d8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8fcc195710>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8fcc195898>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8fcc1959b0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8fcc1959e8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8fcc195b70>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8fcc195c88>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8fcc195cc0>\n",
      "unfreeze: <keras.layers.pooling.GlobalAveragePooling2D object at 0x7f8fcc195cf8>\n",
      "unfreeze: <keras.layers.core.Dense object at 0x7f8fcc195d68>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8fcc195eb8>\n",
      "unfreeze: <keras.layers.core.Dropout object at 0x7f8fcc191fd0>\n",
      "unfreeze: <keras.layers.core.Dense object at 0x7f8fcc199048>\n",
      "unfreeze: <keras.layers.core.Dense object at 0x7f8fcc199198>\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2570        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,841,418\n",
      "Trainable params: 1,184,010\n",
      "Non-trainable params: 14,657,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crea/tf_env/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "resnet50_model = ResNet50(input_shape=(256, 256, 3), weights='imagenet', pooling='avg', include_top=False)\n",
    "last_feature_map = resnet50_model.output\n",
    "\n",
    "x = Dense(512, activation='relu')(last_feature_map)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output_layer = Dense(num_cls, activation='softmax')(x)\n",
    "model = Model(inputs=[resnet50_model.input], outputs=[output_layer])\n",
    "model = load_model('cifar10.h5')\n",
    "#unfreeze partial pretrained parameter\n",
    "l = -26\n",
    "for layer in model.layers[:l]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[l:]:\n",
    "    layer.trainable = True\n",
    "    print('unfreeze:', layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35000 images belonging to 10 classes.\n",
      "Found 15000 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 344s 246ms/step - loss: 0.6262 - acc: 0.7797 - val_loss: 0.5160 - val_acc: 0.8361\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51599, saving model to cifar10_F.h5\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.5656 - acc: 0.8024 - val_loss: 0.4798 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51599 to 0.47978, saving model to cifar10_F.h5\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.5280 - acc: 0.8182 - val_loss: 0.4631 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.47978 to 0.46308, saving model to cifar10_F.h5\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.4996 - acc: 0.8271 - val_loss: 0.4638 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46308\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 352s 251ms/step - loss: 0.4715 - acc: 0.8356 - val_loss: 0.4710 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.46308\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.4428 - acc: 0.8455 - val_loss: 0.4534 - val_acc: 0.8591\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46308 to 0.45338, saving model to cifar10_F.h5\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.4279 - acc: 0.8516 - val_loss: 0.4584 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45338\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 352s 252ms/step - loss: 0.4072 - acc: 0.8595 - val_loss: 0.4624 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45338\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.3839 - acc: 0.8673 - val_loss: 0.4426 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.45338 to 0.44258, saving model to cifar10_F.h5\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 356s 254ms/step - loss: 0.3674 - acc: 0.8742 - val_loss: 0.4593 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44258\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.3496 - acc: 0.8795 - val_loss: 0.4470 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.44258\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 352s 251ms/step - loss: 0.3412 - acc: 0.8807 - val_loss: 0.4478 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.44258\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 352s 251ms/step - loss: 0.3234 - acc: 0.8894 - val_loss: 0.4548 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.44258\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 354s 253ms/step - loss: 0.3090 - acc: 0.8940 - val_loss: 0.4762 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.44258\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 352s 252ms/step - loss: 0.2934 - acc: 0.8971 - val_loss: 0.4749 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.44258\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 353s 252ms/step - loss: 0.2861 - acc: 0.9019 - val_loss: 0.4758 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.44258\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 352s 252ms/step - loss: 0.2854 - acc: 0.8999 - val_loss: 0.4627 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.44258\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 355s 253ms/step - loss: 0.2851 - acc: 0.9009 - val_loss: 0.4725 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.44258\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 355s 253ms/step - loss: 0.2777 - acc: 0.9039 - val_loss: 0.4725 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.44258\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 25\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-5\n",
    "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.1, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "checkpoint = ModelCheckpoint(monitor='val_loss', filepath='cifar10_F.h5', \n",
    "                             save_best_only=True, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator.flow_from_directory('/home/crea/tf_env/train_imgs', \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                      \n",
    "                              epochs=EPOCHS, steps_per_epoch=ceil(len(x_train)/BATCH_SIZE),\n",
    "                              validation_data= test_generator.flow_from_directory('/home/crea/tf_env/valid_imgs',\n",
    "                                                                   batch_size=BATCH_SIZE),\n",
    "                              validation_steps=ceil(len(x_valid)/BATCH_SIZE),\n",
    "                              verbose=1, callbacks=[lr_reducer, early_stop, checkpoint],\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, k in enumerate(['val_acc', 'loss', 'val_loss', 'acc']):\n",
    "    with open('history_F.json', 'a') as f:\n",
    "        json.dump({k:history.history[k]}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "[0.48539899244904516, 0.8603999960422516]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fd1a8c14a20>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4VGXax/HvnU5ICL0HEroQpIXQmw1UBBURsAGKiIKIhV19V1dFXXd1rSsWVFRQFESXRUURBaSXAKFDCCWQACEJEDppz/vHmeAQUgYyyZkk9+e65srMKXPuHIbfnDznOc8RYwxKKaXKBy+7C1BKKVVyNPSVUqoc0dBXSqlyRENfKaXKEQ19pZQqRzT0lVKqHNHQV0qpckRDXymlyhENfaWUKkd87C4gt+rVq5uwsDC7y1BKqVJl3bp1KcaYGoUt53GhHxYWRnR0tN1lKKVUqSIi8a4sp807SilVjmjoK6VUOaKhr5RS5YjHtekrpcqnjIwMEhISOHfunN2leLSAgADq16+Pr6/vFa2voa+U8ggJCQkEBwcTFhaGiNhdjkcyxpCamkpCQgLh4eFX9B7avKOU8gjnzp2jWrVqGvgFEBGqVatWpL+GNPSVUh5DA79wRd1HZSb0085m8OavO4k7csruUpRSymOVmdDPzMpmytI9fPTHbrtLUUqVUkFBQXaXUOzKTOhXC/LnzshQ5sQkcijtrN3lKKWURyozoQ/wYI9GZBuYumyv3aUopUoxYwwTJ04kIiKC1q1bM3PmTAAOHTpEz549adu2LRERESxdupSsrCxGjBhxYdm33nrL5uoLVqa6bIZWDaT/1XWYsXo/4/o0JSTwyvqxKqXs9eIPW9l28IRb37Nl3Uo8f0srl5b9/vvviYmJYePGjaSkpNCxY0d69uzJjBkz6Nu3L3/729/IysrizJkzxMTEkJiYyJYtWwA4fvy4W+t2tzJ1pA8wpldjTqdnMX3VPrtLUUqVUsuWLWPYsGF4e3tTq1YtevXqxdq1a+nYsSOfffYZL7zwAps3byY4OJhGjRqxZ88eHn30UX755RcqVapkd/kFKlNH+gBX1alE7+Y1+Gz5Pkb1aESAr7fdJSmlLpOrR+QlrWfPnixZsoSffvqJESNG8MQTT3DfffexceNG5s+fz4cffsisWbOYOnWq3aXmq8wd6YN1tJ96Op1vow/YXYpSqhTq0aMHM2fOJCsri+TkZJYsWUJUVBTx8fHUqlWLBx98kFGjRrF+/XpSUlLIzs5m0KBBvPzyy6xfv97u8gtU5o70ATqFV6Vdg8pMWbqHYVEN8PEuk99tSqlictttt7Fy5UratGmDiPDaa69Ru3ZtvvjiC15//XV8fX0JCgpi2rRpJCYmMnLkSLKzswF49dVXba6+YGKMsbuGi0RGRhp33ERl/tbDPDR9He8MbcvAtvXcUJlSqjht376dq666yu4ySoW89pWIrDPGRBa2bpk9BL7+qlo0rlGRD//Yg6d9sSmllF3KbOh7eQkP9WrM9kMn+CM22e5ylFLKI7gU+iLST0R2ikiciDydzzJ3isg2EdkqIjOcpg8XkV2Ox3B3Fe6KW9vWo3alAD7UoRmUUgpwIfRFxBuYDNwItASGiUjLXMs0BZ4BuhljWgETHNOrAs8DnYAo4HkRqeLW36AAfj5ejOoRzqo9R9mw/1hJbVYppTyWK0f6UUCcMWaPMSYd+AYYmGuZB4HJxphjAMaYI47pfYEFxpijjnkLgH7uKd01Q6MaUCnAR4/2lVIK10K/HuDc4T3BMc1ZM6CZiCwXkVUi0u8y1i1WQf4+DO8axq/bknTYZaVUueeuE7k+QFOgNzAM+FhEKru6soiMFpFoEYlOTnb/SdfhXcPw8/ZiyhI92ldKlW+uhH4iEOr0ur5jmrMEYK4xJsMYsxeIxfoScGVdjDFTjDGRxpjIGjVqXE79Lqke5M+QjqH8d0Mih9P0pstKqaIraOz9ffv2ERERUYLVuM6V0F8LNBWRcBHxA4YCc3MtMwfrKB8RqY7V3LMHmA/cICJVHCdwb3BMK3E5wy5/umyPHZtXSimPUOgwDMaYTBEZhxXW3sBUY8xWEZkERBtj5vJnuG8DsoCJxphUABF5CeuLA2CSMeZocfwihQmtGsjNrXXYZaVKhZ+fhsOb3fuetVvDjf/Md/bTTz9NaGgoY8eOBeCFF17Ax8eHRYsWcezYMTIyMnj55ZcZODB3P5aCnTt3jocffpjo6Gh8fHx488036dOnD1u3bmXkyJGkp6eTnZ3Nd999R926dbnzzjtJSEggKyuL5557jiFDhhTp187NpbF3jDHzgHm5pv3d6bkBnnA8cq87FfCIIefG9GrM3I0H+XJ1PGP7NLG7HKWUBxkyZAgTJky4EPqzZs1i/vz5jB8/nkqVKpGSkkLnzp0ZMGDAZd2cfPLkyYgImzdvZseOHdxwww3Exsby4Ycf8thjj3H33XeTnp5OVlYW8+bNo27duvz0008ApKWluf33LJMDruWnZd1K9GpWg6nL9vJA93AddlkpT1XAEXlxadeuHUeOHOHgwYMkJydTpUoVateuzeOPP86SJUvw8vIiMTGRpKQkateu7fL7Llu2jEcffRSAFi1a0LBhQ2JjY+nSpQuvvPIKCQkJ3H777TRt2pTWrVvz5JNP8te//pX+/fvTo0cPt/+eZXYYhvw83Nsx7PK6BLtLUUp5mMGDBzN79mxmzpzJkCFD+Oqrr0hOTmbdunXExMRQq1Ytzp1zT2eQu+66i7lz51KhQgVuuukmFi5cSLNmzVi/fj2tW7fm2WefZdKkSW7ZlrNyF/qdwqvSNrQyU5bsJjMr2+5ylFIeZMiQIXzzzTfMnj2bwYMHk5aWRs2aNfH19WXRokXEx8df9nv26NGDr776CoDY2Fj2799P8+bN2bNnD40aNWL8+PEMHDiQTZs2cfDgQQIDA7nnnnuYOHFisYzNX+5CX0R4uHdjDhw9y7wth+0uRynlQVq1asXJkyepV68ederU4e677yY6OprWrVszbdo0WrRocdnv+cgjj5CdnU3r1q0ZMmQIn3/+Of7+/syaNYuIiAjatm3Lli1buO+++9i8eTNRUVG0bduWF198kWeffdbtv2OZHU+/INnZhuvf+gM/H2/mje9+WSdllFLFQ8fTd52Op3+ZvLyEh3pawy4v2ZVidzlKKVViymXoAwxsV9cadnmxDs2glLoymzdvpm3bthc9OnXqZHdZBSpXXTad+ft480D3cF6Zt52YA8dpG+ryUEFKqWJijClVza2tW7cmJiamRLdZ1Cb5cnukDzCsk2PYZT3aV8p2AQEBpKam6u1NC2CMITU1lYCAgCt+j3J7pA/WsMv3dQlj8uI4diefonGN/AdQUkoVr/r165OQkEBxjLRblgQEBFC/fv0rXr9chz7AiG5hfLx0D1P+2MO/7rja7nKUKrd8fX0JDw+3u4wyr1w374A17PKdkaF8vyFBh11WSpV55T70wRp2OSvbMHX5XrtLUUqpYqWhDzSoFkj/q+vy1ap40s5k2F2OUkoVGw19hzG9GnM6PYu3fou1uxSllCo2GvoOLetWYkTXMD5fsY9fdEwepVQZpaHv5JmbWnB1/RAmzt7IgaNn7C5HKaXcTkPfib+PN+8Naw/AuBnrSc/UoZeVUmWLhn4uDaoF8vodbdiYkMarP2+3uxyllHIrDf089IuozchuYXy2XNv3lVJli0uhLyL9RGSniMSJyNN5zB8hIskiEuN4jHKal+U0fa47iy9Oz9x4FW20fV8pVcYUGvoi4g1MBm4EWgLDRKRlHovONMa0dTw+cZp+1mn6APeUXfz8fLx47y6rfX/sjPWcz8yyuSKllCo6V470o4A4Y8weY0w68A0wsHjL8gyhVa32/U0Jabw6b4fd5SilVJG5Evr1gANOrxMc03IbJCKbRGS2iIQ6TQ8QkWgRWSUit+a1AREZ7Vgm2tNG2Mtp37f67x+yuxyllCoSd53I/QEIM8ZcDSwAvnCa19Bx38a7gLdFpHHulY0xU4wxkcaYyBo1aripJPf5s31/E/tTtX1fKVV6uRL6iYDzkXt9x7QLjDGpxpjzjpefAB2c5iU6fu4BFgPtilCvLXLa9wUY97W27yulSi9XQn8t0FREwkXEDxgKXNQLR0TqOL0cAGx3TK8iIv6O59WBbsA2dxRe0kKrBvL6YG3fV0qVboXeRMUYkyki44D5gDcw1RizVUQmAdHGmLnAeBEZAGQCR4ERjtWvAj4SkWysL5h/GmNKZegD9G1Vm/u7hTN1+V46hVflxtZ1Cl9JKaU8iHja/SgjIyNNdHS03WXkKz0zm8EfrWTPkVP8NL4HDaoF2l2SUkohIusc508LpFfkXiY/Hy/eG9YOEe2/r5QqfTT0r0Bo1UD+PbgNmxO1fV8pVbpo6F+hG1rV5oHu4Xy+Yh8/b9b++0qp0kFDvwj+2q8FbUIr85fZm4hPPW13OUopVSgN/SLw8/Fi8l3avq+UKj009IuofpVA3rizLVsST/CPn3T8faWUZ9PQd4PrW9ZiVPdwvlgZz3frEuwuRyml8lXoxVnKNX/p14Jth04wcfZGfLyFgW3zGpNOKaXspUf6buLn48UnwyOJCq/K4zNjmLvxoN0lKaXUJTT03SjQz4epIzrSMawqE77ZwA8a/EopD6Oh72aBfj58NrIjkWFVmTAzhp82aR9+pZTn0NAvBoF+Pnw2oiPtG1Rm/Dcb9OItpZTHKFuhf/IweMgAchX9ffhsZBTtQivz6Ncb9K5bSimPUHZCPyUO3ouCNR/bXckFQf4+fH5/FG1CKzNuxgZ+2XLY7pKUUuVc2Qn9qo0grBvMfwb2r7a7mguC/H34fGRHWtcPYdyM9fy6VYNfKWWfshP6Xl5w6wcQEgrfDodTR+yu6ILgAF++uD+KiHohjJ2xngXbkuwuSSlVTpWd0AeoUBmGfAlnj8O3IyEr0+6KLqgU4Mu0B6JoWTeER75ax+/bNfiVUiWvbIU+QO0IuOUdiF8Gv79gdzUXqRTgy7T7o2hZpxIPf7mehTs0+JVSJavshT5AmyHQ8UFY8R/Y9j+7q7lISAVfpj3QiRZ1ghkzfT2LdnhOM5RSquxzKfRFpJ+I7BSROBF5Oo/5I0QkWURiHI9RTvOGi8gux2O4O4svUN9/QP2OMOcRSI4tsc26IqSCL9Pv70Sz2kE8NH0di3dq8CulSkahoS8i3sBk4EagJTBMRFrmsehMY0xbx+MTx7pVgeeBTkAU8LyIVHFb9QXx8YPBX4BPAMy8B86fKpHNuiok0JcvH+hE01pBjJ6+jj9ik+0uSSlVDrhypB8FxBlj9hhj0oFvgIEuvn9fYIEx5qgx5hiwAOh3ZaVegZB6MPgzSN0Fc8d5zIVbOSoH+vHVqE40qRHEg9OiWaLBr5QqZq6Efj3ggNPrBMe03AaJyCYRmS0ioZe5bvEJ7wnXvQBb/wur3i/RTbsiJ/gbO4J/6S4NfqVU8XHXidwfgDBjzNVYR/NfXM7KIjJaRKJFJDo5uRhCr+t4uOoW+PU52Lfc/e9fRFUqWsEfXr0io77QI36lVPFxJfQTgVCn1/Ud0y4wxqQaY847Xn4CdHB1Xcf6U4wxkcaYyBo1arhau+tEYOD7UDUcZo+0xujxMFUr+jHjwc40qhHEqGnR2savlCoWroT+WqCpiISLiB8wFJjrvICI1HF6OQDIuVnsfOAGEaniOIF7g2NayQuoZF24df4UzBoOWRm2lFGQqhX9mOHUxq+9epRS7lZo6BtjMoFxWGG9HZhljNkqIpNEZIBjsfEislVENgLjgRGOdY8CL2F9cawFJjmm2aPmVTDwP3BgldXU44Fymnqa1gxi9LR12o9fKeVWYjysR0tkZKSJjo4u3o388ox1UnfQp9D6juLd1hU6fiadez5dTezhU3x4b3uuaVHL7pKUUh5MRNYZYyILW65sXpFbmOsnQYMuMPdROLK98OVtUDnQjy8f6ETz2taVuzpWj1LKHcpn6Hv7wuDPwT/YunDr3Am7K8pTTvC3qBPMmC/X8ZuOzqmUKiIfuwtwu969L512553wyCNw5gzcdNOf00MqQdtd8O7NMHEJpKbCHXk09zz8MAwZAgcOwL33Xjr/ySfhlltg50546KFL5z/7LFx3HcTEwIQJl87/xz+ga1dYsQL+7/8umhUCTH/tTe5bAw9Pj+b9Hd9z/bHdF6//0UfQvDn88AO88cal7z99OoSGwsyZ8MEHl86fPRuqV4fPP7ceuc2bB4GB8P77MGvWpfMXL7Z+/vvf8OOPF8+rUAF+/tl6/tJL8PvvF8+vVg2++856/swzsHLlxfPr14cvv7SeT5hg7UNnzZrBlCnW89GjITbXkBtt28Lbb1vP77kHEhIunt+lC7z6qvV80CDrM+Ds2mvhOcf5nxtvhLNnL57fvz889ZT1/HI+ezlGjLAeKSke99kDrH3Xti389hu8/PKl8/WzZz1312cv5/cpRuXzSD9HWhDsrgdnNsHyd+yuJl8hfl5Me6ATLYOFR5oO5NcqTewuSSlVSpXPE7nOjLH67m/7H9w7Bxr1KrltX6YT5zK479M1bElM47272tMvorbdJSmlPISeyHWVCAx4D6o1hdn3Q+ruwtexSc6NWHJuvag3W1dKXS4NfQD/IOvCrawMeL8LLHwF0s/YXVWecm7EcnX9EMbO2MDPmzX4lVKu0+YdZycOwoK/w+ZvrXvt3vAytBxo/TXgYU6ey2DEZ2uJOXCcd4e24+ar6xS+klIFiV8ByTvBr6L18A0EvyDwC3S8zpleoWj/J4yB7EzIPG89ss5D5jnITLdGxvUPdt/vVI642ryjoZ+Xfcvh579A0hYI7wU3vgY1W9hbUx5Onc9kxNQ1bDhwnHeGtqX/1XXtLkmVRlkZ8PskWPGuiyuI05dCxYu/JET+DPPcgZ55DrIcP0123m/tFwyRI6DzI1BJP8+XQ0O/qLIyYd1nsPAlSD8NUQ9B779CQIjdlV3k1PlMRn62hvX7j/P2kLbc0kb/o6jLkJZodWQ4sBo6joJuE6ywTj8FGWesz37OI+OMNT39zMXP009DhmMZAG9/8HF6XHgdYN3cyCcg72W8fWHnPGsYdPGGq4dAt/FQo3nx7wdj4PBmOLYvZ8Kf01167RBYDRr3Kb46C6Ch7y6nU6yjoPXToGINuP5FuHooeHnO6ZDTZ8/x8sff4Je0nj59b6d3z952l6RKg7jf4fsHrZC/5R3PGZLk2D5Y8R5s+BIyz0Lzm6DbY9Cgs/u3lRwLW76DLbMhNa7o79egC9z/S9Hf5wpo6Ltb4nqYNxESo6F+FNz0OtRta08t2dlW09PeJbBvqdUWe966qjjTeBHf/H4a3zHJ+pNbqdyys2DxP2HJ69YghHdOg+pN7a7qUqdTYM3HsOYjOHsMQjtb4d+sX9EOuo7vhy3fW0F/eDMgENYdIgZBvQ4gjve+cN5CXH/tEwCVnUeTLzka+sUhOxs2fg2/PW99IDsMh2v+DhWrFe92jYHkHbB3Kez9A+KXW/8JAKo2su4OFtaDM9VasWL6C1x39hfOBNYj8LZ3oOn1xVubKl1OJsF3D1gHC23vsQ5e/ALtrqpg6aeto/4V70Hafqje3Gr2aX2n1VzkilNHYOscK+gPrLam1Yu0gr7VbVCp9HeE0NAvTufSrCOl1R9ZPQ2ueRYi7wcvb/e8vzFwdI91JL93CexbBqcdQyyHNLBCPrwHhPWwejs4OXU+k1c/+JSRx96hiSRaH+h+/4RgvZCr3Nu71Ar8cyfg5n9Du3vsrujyZGVYwb38HUjaDMF1rBO+HUZY98vI7exx2P6DFfR7l1gnj2u2gojbrbCvGl7iv0Jx0tAvCUe2W00++5ZCrdbWUVNolKPXQrqjp0Iez/Obn34GEtdZH9CTB61tBNexwj0n6KuEFVrWiXMZjPxkOd2TvmS87//w9g2A656HDvd71LkIVUKys2HZm7DoFajaGO78Amq1sruqK2cM7P7dCv+9S8A/BDreD50etq652fmz1XwTt8D6f1UlDCLusM5Z1LzK7uqLjYZ+STEGts2B+c/CiYTCly9MYPU/j+LDe0G1xlfUJzrtbAb3fLKac4djmVX/W6okrYD6HaH/21A7ouh1ukNWhtW+enSP9Ti+H5pcC42vsbuysuPMUfh+tBWAEYOsE7ZlqR984jpY/i5snwtePuDla/UkCq4DrW6H1oOgbnuPvNbG3TT0S1r6aVg/Hc4dB28/Rzc0p58Xnvtb7ZB5TvOHoJpu+4AeP5PO3Z+sZteRk8ztmUiLmFetP3m7joNefy2ZE705wZ662xHujp+pu63pJuvPZcXbet3xQeueB57e1uzpDqyBb0daTYP9XoXIB8pu+KXuhjVTrM9bxO1WLxp3NbeWEhr6CoBjp9MZ9vEq9qacZvqwJkTFvQMbpkPlBnDzm+450WuMdTXzkW1WtzfngD9+4OJg9wuGao2sE9BVGzt+NrL+ovGvZHWPXTUZqjeD2z8uuR5SR7Zb52kCQqDTGKjVsmS2WxyMse4Mt+DvUKme1ZxTt53dValipqGvLkg9dZ67Pl5N/NHTfD4yis5eO+DHCZASe/knes+ftAIyaQskbbOCPmmLdXI7h3+li8PcOeArVi/8aHP3IpjzMJxOhj7/Z10wVFxHbWePW2G/ZorVHpyZbvUND+8FnR+Gpn1L13mQs8fhf2Nhx4/Q/Ga4dTJUqGJ3VaoEaOiri6ScOs+wKatIPH6Wz0dGERVa0WoLXfK61cSU+0RvVqZ1pJ473I/v//NN/YKtI+KaLa0Tg7VaWUfogdWK3oxw5ij8+Lh1vqRBF7jtI6jSsGjv6Sw7GzbOgN9ecHS/HQHXPGfVve5zWPsJnEiEKuHQ6SFoe3fePUQ8RXYW7F9pBX5aAlz3InQZW3abc9Ql3Br6ItIPeAfwBj4xxvwzn+UGAbOBjsaYaBEJA7YDOx2LrDLGjCloWxr6xefIyXMMnbKKpLRzTHsgig4Nq1pNMT8+bvX/rxdpXaSTtMW6UjHrvLWieFvTncO9Zkuriag4Q8UY2DQTfnLcmeqm16HN0KJvM3EdzPuLdaFdaCdrbKXczUhZGVZ3v9UfWv26/YKh3d0QNdr668VuWRlwMMa6ZiN+OexfZV2gV6ke3PEZNOhkd4WqhLkt9EXEG4gFrgcSgLXAMGPMtlzLBQM/AX7AOKfQ/9EY43J3EQ394pV0wgr+5JPnmf5AFO0aVHGE6yyrDVjEEe4toVaE9bxGc+uvAbsci4f/joH9K6DlrdD/LQisevnvcyoZfn/RutAnqKZ1svjqIYV/iSSut8J/y/fW6JDN+kHnMVYTUEkdSWeet+qIX2YNCHhgjdVLBax7QYR1g4bdrXM0FSqXTE3Ko7gz9LsALxhj+jpePwNgjHk113JvAwuAicBTGvqe63DaOYZMWcnRU+l8OaoTbUIdIWGM5zYHZGdZ/bIX/cM6L3DrB64PbJWVaTXXLPqHFZSdH4aef7n85pqThyF6qvU4nWx9IXZ6yLoy1N09jTLOQsJaK+Djl1vPM89Z82q2hIbdHEHfzfoCU+WeO0P/DqCfMWaU4/W9QCdjzDinZdoDfzPGDBKRxVwc+lux/lI4ATxrjFmaxzZGA6MBGjRo0CE+Pt6lX1JduYPHzzJkykrSzmQw48HORNTzrNFD83Uwxup3nrLTuhrz2ufBNyD/5fcutYbJPrINGvWxmnJqNCtaDRnnYOv3Vg+Zw5utE6UdRlhdTXNdIU12dv7DC+e8zpmWcRaStlohn7jOmoZA7dbW2DANu1nnN4p72A9VKpVY6IuIF7AQGGGM2Zcr9P2BIGNMqoh0AOYArYwxJ/Lbnh7pl5yEY2cY8tEqTp3PZMaDnWhVt5QEf8ZZWPC8NRBXjatg0MdWMDpLS4Rfn7XCuXID6PsPaNHfvX/JGGMNdrf6A9jxEyBWL6jMc3+OJ5+dcXnvKd7W+YWGjqP4Bp21uUa5pMSad0QkBNgNnHKsUhs4CgwwxkTneq/FOL4Q8tuehn7J2p96hqFTVnI2I4uvR3emRW0P7qGS267f4H+PWIPPXfMcdBlnheyK/8DSN6yxVro/bo3M6FuheGs5Fg/rv4BTSY6L7QLyGVPeMc/bL+9lKoeWrStmVYlxZ+j7YDXPXAskYp3IvcsYszWf5Rfz55F+DeCoMSZLRBoBS4HWxpij+W1PQ7/kxaeeZshHq8jIymbKfR2sXj2lxelU+GG81S+9QVc4ddi6MOyqW+CGV9zbzVMpD+Zq6Bd61YkxJhMYB8zH6n45yxizVUQmiciAQlbvCWwSkRisrpxjCgp8ZY+G1Sry9ejO+Pl4MeiDlYyeFs2upJN2l+WaitWsm9oPnAyHN1njr9z7X2uaBr5Sl9CLs9QFp89nMnXZXqYs2cPp9Exub1+fCdc1pX6VUjIGzrkT1n1avX3srkSpEqdX5KordvR0Oh8sjuOLlfFg4O7ODRjbpwnVg2zsq6+UKpCGviqyg8fP8u7vu5gVfYAKvt6M6tGIUT3CCQ7wtbs0pVQuGvrKbXYnn+LNX2P5afMhqgT6MrZPE+7p3JAA3/I1dK1SnkxDX7ndpoTjvD5/J0t3pVA3JIAJ1zXj9vb18PEuRaNQKlVGua33jlI5rq5fmekPdGLGqE7UqBTAX77bRN+3l/Dz5kN42sGDUipvGvrqsnVtUp05j3Tlw3s6ICI8/NV6bp28nOVxKXaXppQqhIa+uiIiQr+I2vzyWA9eu+Nqkk+e5+5PVjP2q/Wknb3MoQeUUiVGQ18ViY+3F3dGhrLwqd5M7Nuc+VsPc9M7S1kXr9fgKeWJNPSVWwT4ejO2TxO+HdMFLy+486NVTF4UR1a2tvUr5Uk09JVbtWtQhZ/G9+DGiNq8Pn8n9366mqQT5+wuSynloKGv3K5SgC//GdaOfw1qzfr9x7jxnaUs2nHE7rKUUmjoq2IiIgzp2IAfH+1OzWB/Rn6+lpd+3Mb5zCy7S1OqXNPQV8WqSc1g5oztxn1dGvLpsr0M+mAFe1NO212WUuWWhr4qdgG+3kwaGMFH93bgwNGz9H93Kf/dkGB3WUqVSxr6qsT0bVWbnx/rQau6ITw+cyNPzIrh1PlMu8tSqlzR0FdDBWJGAAAUPElEQVQlqm7lCsx4sBOPXduUORsSueU/y9iSmGZ3WUqVGxr6qsT5eHvx+PXNmPFgZ86mZ3Hb+8v5dNleHb9HqRKgoa9s07lRNX5+rAe9mtXkpR+38cAX0Rw9nW53WUqVaRr6ylZVKvrx8X0deHFAK5btSmHAe8vYcfiE3WUpVWa5FPoi0k9EdopInIg8XcByg0TEiEik07RnHOvtFJG+7ihalS0iwvCuYXw7pgvpmdkMen8FC7Yl2V2WUmVSoaEvIt7AZOBGoCUwTERa5rFcMPAYsNppWktgKNAK6Ae873g/pS7RJrQyc8d1p3HNIEZPj+b9xXHazq+Um7lypB8FxBlj9hhj0oFvgIF5LPcS8C/AeaCVgcA3xpjzxpi9QJzj/ZTKU+2QAGY91IX+V9fltV928vjMGM5l6FW8SrmLK6FfDzjg9DrBMe0CEWkPhBpjfrrcdZXKLcDXm3eHtmVi3+bMiTnIkCmrOKKDtinlFkU+kSsiXsCbwJNFeI/RIhItItHJyclFLUmVASLC2D5N+PCeDuxKOsmA95azOUH78ytVVK6EfiIQ6vS6vmNajmAgAlgsIvuAzsBcx8ncwtYFwBgzxRgTaYyJrFGjxuX9BqpM6xdRm9ljuuLtJQz+aAU/bjpod0lKlWquhP5aoKmIhIuIH9aJ2bk5M40xacaY6saYMGNMGLAKGGCMiXYsN1RE/EUkHGgKrHH7b6HKtJZ1K/G/cd2IqBvCuBkbeHNBLNl6cxalrkihoW+MyQTGAfOB7cAsY8xWEZkkIgMKWXcrMAvYBvwCjDXG6Fk5ddmqB/nz1YOdGNyhPu/+vouxM9ZzJl3H7VHqcomndYmLjIw00dHRdpehPJQxhk+X7eUf87bTonYlPh4eSb3KFewuSynbicg6Y0xkYcvpFbmqVBERRvVoxKcjOnLg6BkGvrecdfHH7C5LqVJDQ1+VSn2a1+S/Y7tS0d+bYVNWMXudjs+vlCs09FWp1aRmMHMe6UZkWBWe+nYjr87bTpae4FWqQBr6qlSrUtGPL+6P4t7ODfloyR4Gf7hC+/MrVQANfVXq+Xp78dKtEbwxuA3xqWcYMHkZz3y/idRT5+0uTSmPo6GvyoxBHeqz8Kne3N8tnG+jE+j978VMXbaXjKxsu0tTymNo6KsyJaSCL8/1b8nPj/WgbWhlJv24jZveWcqyXSl2l6aUR9DQV2VS01rBTLs/iin3duBcZhb3fLqah6ZHc+DoGbtLU8pWGvqqzBIRbmhVmwWP92Ji3+YsiU3h2jf/4M1fd+rVvKrc0tBXZV6Arzdj+zRh4VO96NeqNu8ujOPaN/7gh40H9SYtqtzR0FflRp2QCrw7rB2zHupClUA/Hv16A0OmrGLbQb0nryo/NPRVuRMVXpUfHu3OK7dFsCvpJP3/s5Rn52zm2Ol0u0tTqthp6KtyydtLuLtTQxY/1Yf7uoTx9ZoD9P73Yr5cFa/DNqsyTUNflWshgb68MKAV88b34Ko6wTw7ZwuDP1rJzsMn7S5NqWKhoa8U0Lx2MF8/2Jl/D27DnuRT3PzuUl6fv0Nvyq7KHA19pRxEhDs61Of3J3szoG1dJi/aTb+3l7A8Ti/sUmWHhr5SuVSt6Mebd7blq1GdALj7k9U8MTNGx/JRZYKGvlL56NakOr9M6Mm4Pk2Yu/Eg1735B99GH9C+/apU09BXqgABvt481bc58x7rQaMaQUycvYm7Pl7NnuRTdpem1BVxKfRFpJ+I7BSROBF5Oo/5Y0Rks4jEiMgyEWnpmB4mImcd02NE5EN3/wJKlYRmtYL59qEuvHJbBFsOptHvnaW8+/su0jN1BE9VuhR6Y3QR8QZigeuBBGAtMMwYs81pmUrGmBOO5wOAR4wx/UQkDPjRGBPhakF6Y3Tl6Y6cOMeLP27jp02HaFIziFdvb03HsKp2l6XKOXfeGD0KiDPG7DHGpAPfAAOdF8gJfIeKgDZ6qjKrZqUAJt/Vns9GdORsehaDP1zJM99vIu1Mht2lKVUoV0K/HnDA6XWCY9pFRGSsiOwGXgPGO80KF5ENIvKHiPQoUrVKeZA+LWqy4ImePNgjnJlrD3Dtm3/w0R+7iTtySk/2Ko/lSvPOHUA/Y8wox+t7gU7GmHH5LH8X0NcYM1xE/IEgY0yqiHQA5gCtcv1lgIiMBkYDNGjQoEN8fHxRfy+lStSWxDSen7uVdfHHAGhYLZBrWtTk2ha1iAqvip+P9plQxcvV5h1XQr8L8IIxpq/j9TMAxphX81neCzhmjAnJY95i4CljTL6N9tqmr0qzxONnWbjjCAu3J7F8dyrpmdkE+fvQvUl1rrmqJn2a16RGsL/dZaoyyNXQ93HhvdYCTUUkHEgEhgJ35dpYU2PMLsfLm4Fdjuk1gKPGmCwRaQQ0Bfa4/msoVbrUq1yBezs35N7ODTmTnsmKuFQW7jzCwu1H+GXrYQDahFbm2hY1uaZFTVrVrYSI2Fy1Kk8KPdIHEJGbgLcBb2CqMeYVEZkERBtj5orIO8B1QAZwDBhnjNkqIoOASY7p2cDzxpgfCtqWHumrssgYw7ZDJ1i4/Qi/7zjCxoTjGAO1KvlzTYuaXNOiFt2aVCPQz5XjMKUu5bbmnZKmoa/Kg5RT51m8M5mFO5JYEpvCqfOZ+Pl4Mah9PZ7udxUhgb52l6hKGQ19pUqJ9Mxs1u47yrzNh/hm7QGqBPryXP+WDGhTV5t+lMvc2U9fKVWM/Hy86NakOq/c1pq547pRr3IFHvsmhuGfreXA0TN2l6fKGA19pTxIq7ohfP9IN56/pSXr9h3l+resvv+ZWTrcg3IPDX2lPIy3lzCyWzgLnuhF9yY1ePXnHQx4bzkbDxy3uzRVBmjoK+Wh6lauwMf3deDDe9qTcuo8t72/nBfmbuXU+Uy7S1OlmIa+Uh5MROgXUYffnuzF3Z0a8sXKfVz/5h8s2JZkd2mqlNLQV6oUqBTgy0u3RjB7TFcqBfjy4LRoHv5yHUknztldmiplNPSVKkU6NKzCD492Z2Lf5vy+4wjXvfEH01fFk53tWV2vlefS0FeqlPHz8WJsnyb8OqEnV4eG8NycLdzx4Qp2Hj5pd2mqFNDQV6qUCqtekS8f6MQbg9uwN+U0N7+7lJd+3EaK3sBdFUBDX6lSTEQY1KE+vz/Zm9vb1+Oz5Xvp8a9F/PPnHRw7nW53ecoD6TAMSpUhcUdO8e7vu/hh00ECfb25v3s4o7o30rF8ygEde0epciw26SRv/xbLvM2HCQ7wYVT3RozsHkalAA3/skpDXynFtoMnePu3WH7dlkRIBV9G92zE8K5hBPnrEM5ljYa+UuqCzQlpvPVbLAt3HKFqRT8e6tmIe7s01PH7yxANfaXUJTbsP8Zbv+1iSWwy1YP8GNOrMfd0bkiAr7fdpaki0tBXSuVr7b6jvLUglhW7U6kZ7M/YPk0YGhWKv4+Gf2mloa+UKtTK3am8tSCWNfuOUickgPHXNmVwh/r4eGtv7tJGb6KilCpUl8bVmPlQZ758oBO1QwJ45vvN3PTuUhbtPIKnHRAq99DQV6qcExG6N63O9w935YO723M+M5uRn63l3k/XsPVgmt3lKTdzKfRFpJ+I7BSROBF5Oo/5Y0Rks4jEiMgyEWnpNO8Zx3o7RaSvO4tXSrmPiHBj6zoseLwXf+/fki0H0+j/n2U8OWsjh9LO2l2ecpNC2/RFxBuIBa4HEoC1wDBjzDanZSoZY044ng8AHjHG9HOE/9dAFFAX+A1oZozJym972qavlGdIO5vB+4vi+Gz5Pry8YFT3Rozp3Vj7+Hsod7bpRwFxxpg9xph04BtgoPMCOYHvUBHI+SYZCHxjjDlvjNkLxDneTynl4UIq+PLMTVfx+5O9uKFlbd5bFEfv1xcxfVW83rO3FHMl9OsBB5xeJzimXURExorIbuA1YPxlrjtaRKJFJDo5OdnV2pVSJSC0aiDvDmvH/8Z2o1GNIJ6bs4W+by/ht21JerK3FHLbiVxjzGRjTGPgr8Czl7nuFGNMpDEmskaNGu4qSSnlRm1CKzNzdGem3NsBY2DUtGiGfbyKzQl6src0cSX0E4FQp9f1HdPy8w1w6xWuq5TyYCLCDa1qM//xnkwa2IrYpFPc8t4yHp8ZQ+JxPdlbGrgS+muBpiISLiJ+wFBgrvMCItLU6eXNwC7H87nAUBHxF5FwoCmwpuhlK6Xs5OvtxX1dwlg8sTeP9G7MvM2H6PPvxTz17UbmbEjkiN6712MVehreGJMpIuOA+YA3MNUYs1VEJgHRxpi5wDgRuQ7IAI4Bwx3rbhWRWcA2IBMYW1DPHaVU6VIpwJe/9GvBPZ0b8vZvsczfmsTsdQkANKkZRLfG1ejSuDpdGlXTMf09hA7DoJRym6xsw7aDJ1ixO4Xlu1NZu/coZzOy8BKIqBdCl8bV6Na4Oh3DqlLBT8f5cScde0cpZbv0zGxiDhxneVwKK3ensuHAMTKyDL7eQrsGVejWuDrdmlSjTWhlfHW8nyLR0FdKeZwz6Zms2XuUlbtTWb47ha0HT2AMBPp5ExVelcY1gvDz8cLX2ws/b/nz+YVpXrmmyUXTfL0FEcFLBC8BLxHE8dNLBC8vp+eCY9k/pwX4eiEidu+mK+Jq6OuldUqpEhPo50Pv5jXp3bwmAMfPpLNqTyrL41JZsTuF6H3HSM/MJt2mi7+qVvSjS6NqdG1iNUM1rBZYar8E8qOhr5SyTeVAP/pF1KFfRJ2LphtjyMgyZGRlk5GVfeGLID0zm4wsc+F1xoVp1s/MbEO2MRgD2caQnfMz+8/nxnm6sbaVlW3IMoa4I6dYEZfKT5sPAVCvcgW6NalGtybV6dK4GjWDA+zYTW6loa+U8jgigp+P1bxT0owx7Ek5zYq4FJbHpTJ/axKzoq0eSc1qBdG1cXW6NalOp0ZVS+WN5rVNXymlCpDTI2n57hSWx6Wwdt9RzmVk4+0ltK4XYv0l0Lg67RtWsfW2k3oiVymlisH5zCw27D/OirgUlsWlsDEhjaxsg7+PFzdG1Obtoe1sqUtP5CqlVDHw9/Gmc6NqdG5UjSduaM7Jcxms2XuU5XGpBPl7/rUHGvpKKVUEwQG+XHtVLa69qpbdpbhEr4ZQSqlyRENfKaXKEQ19pZQqRzT0lVKqHNHQV0qpckRDXymlyhENfaWUKkc09JVSqhzxuGEYRCQZiC/CW1QHUtxUTnHQ+opG6ysara9oPLm+hsaYGoUt5HGhX1QiEu3K+BN20fqKRusrGq2vaDy9Pldo845SSpUjGvpKKVWOlMXQn2J3AYXQ+opG6ysara9oPL2+QpW5Nn2llFL5K4tH+koppfJRKkNfRPqJyE4RiRORp/OY7y8iMx3zV4tIWAnWFioii0Rkm4hsFZHH8limt4ikiUiM4/H3kqrPqYZ9IrLZsf1LblUmlncd+3CTiLQvwdqaO+2bGBE5ISITci1TovtQRKaKyBER2eI0raqILBCRXY6fVfJZd7hjmV0iMrwE63tdRHY4/v3+KyKV81m3wM9CMdb3gogkOv0b3pTPugX+fy/G+mY61bZPRGLyWbfY959bGcfd4UvLA/AGdgONAD9gI9Ay1zKPAB86ng8FZpZgfXWA9o7nwUBsHvX1Bn60eT/uA6oXMP8m4GdAgM7Aahv/vQ9j9UG2bR8CPYH2wBanaa8BTzuePw38K4/1qgJ7HD+rOJ5XKaH6bgB8HM//lVd9rnwWirG+F4CnXPj3L/D/e3HVl2v+G8Df7dp/7nyUxiP9KCDOGLPHGJMOfAMMzLXMQOALx/PZwLUiIiVRnDHmkDFmveP5SWA7UK8ktu1mA4FpxrIKqCwidWyo41pgtzGmKBfsFZkxZglwNNdk58/ZF8CteazaF1hgjDlqjDkGLAD6lUR9xphfjTGZjpergPru3q6r8tl/rnDl/3uRFVSfIzvuBL5293btUBpDvx5wwOl1ApeG6oVlHB/6NKBaiVTnxNGs1A5YncfsLiKyUUR+FpFWJVqYxQC/isg6ERmdx3xX9nNJGEr+/9ns3oe1jDGHHM8PA3ndL89T9uP9WH+55aWwz0JxGudofpqaT/OYJ+y/HkCSMWZXPvPt3H+XrTSGfqkgIkHAd8AEY8yJXLPXYzVXtAH+A8wp6fqA7saY9sCNwFgR6WlDDQUSET9gAPBtHrM9YR9eYKy/8z2yK5yI/A3IBL7KZxG7PgsfAI2BtsAhrCYUTzSMgo/yPf7/krPSGPqJQKjT6/qOaXkuIyI+QAiQWiLVWdv0xQr8r4wx3+eeb4w5YYw55Xg+D/AVkeolVZ9ju4mOn0eA/2L9Ge3Mlf1c3G4E1htjknLP8IR9CCTlNHk5fh7JYxlb96OIjAD6A3c7vpgu4cJnoVgYY5KMMVnGmGzg43y2a/f+8wFuB2bmt4xd++9KlcbQXws0FZFwx5HgUGBurmXmAjm9JO4AFub3gXc3R/vfp8B2Y8yb+SxTO+ccg4hEYf07lOSXUkURCc55jnXCb0uuxeYC9zl68XQG0pyaMkpKvkdYdu9DB+fP2XDgf3ksMx+4QUSqOJovbnBMK3Yi0g/4CzDAGHMmn2Vc+SwUV33O54huy2e7rvx/L07XATuMMQl5zbRz/10xu88kX8kDq2dJLNZZ/b85pk3C+nADBGA1CcQBa4BGJVhbd6w/8zcBMY7HTcAYYIxjmXHAVqyeCKuAriW8/xo5tr3RUUfOPnSuUYDJjn28GYgs4RorYoV4iNM02/Yh1pfPISADq135AazzRL8Du4DfgKqOZSOBT5zWvd/xWYwDRpZgfXFY7eE5n8OcHm11gXkFfRZKqL7pjs/WJqwgr5O7PsfrS/6/l0R9jumf53zmnJYt8f3nzodekauUUuVIaWzeUUopdYU09JVSqhzR0FdKqXJEQ18ppcoRDX2llCpHNPSVUqoc0dBXSqlyRENfKaXKkf8H35Q7gcg+ukwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 100\n",
    "score = model.evaluate_generator(test_generator.flow_from_directory('/home/crea/tf_env/test_imgs', \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                                  ceil(len(x_test)/BATCH_SIZE),\n",
    "                    \n",
    "                        )\n",
    "print(score)\n",
    "\n",
    "#for k in ['val_acc', 'loss', 'val_loss', 'acc']:\n",
    "#    with open('history_'+k+'.json', 'w') as f:\n",
    "#        json.dump(history.history[k], f)\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "plt.hlines(score[0], 0, len(history.history['loss']), linestyle='--', color='r')\n",
    "history_df[['acc', 'val_acc']].plot()\n",
    "plt.hlines(score[1], 0, len(history.history['acc']), linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "[0.4560253711044788, 0.8616999965906144]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('cifar10_F.h5')\n",
    "BATCH_SIZE = 100\n",
    "score = model.evaluate_generator(test_generator.flow_from_directory('/home/crea/tf_env/test_imgs', \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                                  ceil(len(x_test)/BATCH_SIZE),\n",
    "                    \n",
    "                        )\n",
    "print(score)\n",
    "#history_df = pd.DataFrame(history.history)\n",
    "#history_df[['loss', 'val_loss']].plot()\n",
    "#plt.hlines(score[0], 0, len(history.history['loss']), linestyle='--', color='r')\n",
    "#history_df[['acc', 'val_acc']].plot()\n",
    "#plt.hlines(score[1], 0, len(history.history['acc']), linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnFreeze ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfreeze: <keras.engine.input_layer.InputLayer object at 0x7f8f6d8af390>\n",
      "unfreeze: <keras.layers.convolutional.ZeroPadding2D object at 0x7f8f6d8afcf8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8af9e8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a8390>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a8d30>\n",
      "unfreeze: <keras.layers.convolutional.ZeroPadding2D object at 0x7f8f6d8a8d68>\n",
      "unfreeze: <keras.layers.pooling.MaxPooling2D object at 0x7f8f6d8a8f60>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a8c50>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a8a58>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a89e8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a8dd8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a8780>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a8ba8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a85c0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a8748>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a8048>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a80f0>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d8a81d0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8afe80>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a05f8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a0550>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a00f0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a0048>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a00b8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a0128>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a05c0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a0eb8>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d8a0710>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a0f28>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a07b8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a0c50>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a0ef0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a0da0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8a0d68>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8a0a20>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a0f98>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8979e8>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d897e80>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d897f28>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d897b00>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d897a58>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d897eb8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d897c50>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d897748>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d897518>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d897710>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8972b0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d897390>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d897780>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d897898>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d897588>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8a82e8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d892e80>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d892dd8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d892f98>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8923c8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d892208>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8928d0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d892080>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d8925f8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8924e0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d892470>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d892a90>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d892320>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8925c0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d892630>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8922e8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d892b70>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d88bef0>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d88b6a0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d88ba58>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d88b9e8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d88bdd8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d88b358>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d88bda0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d88b7f0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d88be10>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d88bd68>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d88bc88>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d88b320>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d88b908>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d88b828>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d88b780>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d88b080>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d88b1d0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d885198>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8852b0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d885390>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d885278>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d885518>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d885ef0>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d885e48>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d885588>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d885da0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d885a90>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d885f28>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d885860>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d885908>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d885b00>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d885668>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e64a518>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6e64a940>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e64a4e0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e64a2e8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e64a3c8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e64a208>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e64a898>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e64a7b8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e64a710>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e64a240>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e64a438>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6e64afd0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e64add8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e64ad68>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e64af98>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e64ab70>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e64aac8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e6432b0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e6435c0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e643a58>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e643780>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6e6435f8>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e643668>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e643198>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e643748>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e6430b8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e643b38>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e643978>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e643630>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e643710>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e643e80>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6e643da0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e643e10>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e643d68>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e653fd0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e6536d8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e653e10>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e653da0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e653828>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e653e80>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e653b70>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6e653240>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e6536a0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e6532e8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e6530f0>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e6535c0>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e653630>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e653438>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e653320>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e653080>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e660208>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8971d0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d9266a0>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6dd84550>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6db60d68>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e65a3c8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e65a358>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e65a160>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e65a0f0>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e65aa20>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e65ab38>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e65ab00>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6e65a5f8>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6e65ad30>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6e65aa90>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6e65af60>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8dc160>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8dcd68>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8dccf8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8dce48>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8dceb8>\n",
      "unfreeze: <keras.layers.convolutional.Conv2D object at 0x7f8f6d8dcdd8>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8dcb00>\n",
      "unfreeze: <keras.layers.merge.Add object at 0x7f8f6d8dc278>\n",
      "unfreeze: <keras.layers.core.Activation object at 0x7f8f6d8dc208>\n",
      "unfreeze: <keras.layers.pooling.GlobalAveragePooling2D object at 0x7f8f6d8dc048>\n",
      "unfreeze: <keras.layers.core.Dense object at 0x7f8f6d8cb438>\n",
      "unfreeze: <keras.layers.normalization.BatchNormalization object at 0x7f8f6d8cb390>\n",
      "unfreeze: <keras.layers.core.Dropout object at 0x7f8f6d8cbf98>\n",
      "unfreeze: <keras.layers.core.Dense object at 0x7f8f6d8cbc88>\n",
      "unfreeze: <keras.layers.core.Dense object at 0x7f8f6d8cb828>\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2570        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,169,482\n",
      "Trainable params: 10,115,338\n",
      "Non-trainable params: 54,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "resnet50_model = ResNet50(input_shape=(256, 256, 3), weights='imagenet', pooling='avg', include_top=False)\n",
    "last_feature_map = resnet50_model.output\n",
    "\n",
    "x = Dense(512, activation='relu')(last_feature_map)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output_layer = Dense(num_cls, activation='softmax')(x)\n",
    "model = Model(inputs=[resnet50_model.input], outputs=[output_layer])\n",
    "model = load_model('cifar10_F.h5')\n",
    "#unfreeze partial pretrained parameter\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    print('unfreeze:', layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35000 images belonging to 10 classes.\n",
      "Found 15000 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "1750/1750 [==============================] - 381s 218ms/step - loss: 0.3271 - acc: 0.8857 - val_loss: 0.2242 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22420, saving model to cifar10_F.h5\n",
      "Epoch 2/100\n",
      "1750/1750 [==============================] - 392s 224ms/step - loss: 0.2480 - acc: 0.9149 - val_loss: 0.1790 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22420 to 0.17899, saving model to cifar10_F.h5\n",
      "Epoch 3/100\n",
      "1750/1750 [==============================] - 402s 229ms/step - loss: 0.2014 - acc: 0.9307 - val_loss: 0.1569 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17899 to 0.15687, saving model to cifar10_F.h5\n",
      "Epoch 4/100\n",
      "1750/1750 [==============================] - 404s 231ms/step - loss: 0.1631 - acc: 0.9455 - val_loss: 0.1570 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15687\n",
      "Epoch 5/100\n",
      "1750/1750 [==============================] - 405s 231ms/step - loss: 0.1390 - acc: 0.9537 - val_loss: 0.1477 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15687 to 0.14770, saving model to cifar10_F.h5\n",
      "Epoch 6/100\n",
      "1750/1750 [==============================] - 403s 230ms/step - loss: 0.1162 - acc: 0.9595 - val_loss: 0.1439 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14770 to 0.14394, saving model to cifar10_F.h5\n",
      "Epoch 7/100\n",
      "1750/1750 [==============================] - 404s 231ms/step - loss: 0.0952 - acc: 0.9679 - val_loss: 0.1502 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14394\n",
      "Epoch 8/100\n",
      "1750/1750 [==============================] - 405s 231ms/step - loss: 0.0836 - acc: 0.9718 - val_loss: 0.1493 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14394\n",
      "Epoch 9/100\n",
      "1750/1750 [==============================] - 406s 232ms/step - loss: 0.0695 - acc: 0.9770 - val_loss: 0.1511 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14394\n",
      "Epoch 10/100\n",
      "1750/1750 [==============================] - 405s 231ms/step - loss: 0.0619 - acc: 0.9803 - val_loss: 0.1587 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14394\n",
      "Epoch 11/100\n",
      "1750/1750 [==============================] - 403s 231ms/step - loss: 0.0579 - acc: 0.9806 - val_loss: 0.1452 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.14394\n",
      "Epoch 12/100\n",
      "1750/1750 [==============================] - 405s 231ms/step - loss: 0.0467 - acc: 0.9847 - val_loss: 0.1351 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.14394 to 0.13511, saving model to cifar10_F.h5\n",
      "Epoch 13/100\n",
      "1750/1750 [==============================] - 404s 231ms/step - loss: 0.0394 - acc: 0.9873 - val_loss: 0.1327 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.13511 to 0.13269, saving model to cifar10_F.h5\n",
      "Epoch 14/100\n",
      "1750/1750 [==============================] - 403s 230ms/step - loss: 0.0388 - acc: 0.9869 - val_loss: 0.1307 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.13269 to 0.13072, saving model to cifar10_F.h5\n",
      "Epoch 15/100\n",
      "1750/1750 [==============================] - 407s 232ms/step - loss: 0.0352 - acc: 0.9886 - val_loss: 0.1319 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13072\n",
      "Epoch 16/100\n",
      "1750/1750 [==============================] - 405s 232ms/step - loss: 0.0329 - acc: 0.9903 - val_loss: 0.1324 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.13072\n",
      "Epoch 17/100\n",
      "1750/1750 [==============================] - 404s 231ms/step - loss: 0.0302 - acc: 0.9909 - val_loss: 0.1324 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.13072\n",
      "Epoch 18/100\n",
      "1750/1750 [==============================] - 406s 232ms/step - loss: 0.0304 - acc: 0.9910 - val_loss: 0.1301 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.13072 to 0.13013, saving model to cifar10_F.h5\n",
      "Epoch 19/100\n",
      "1750/1750 [==============================] - 402s 230ms/step - loss: 0.0291 - acc: 0.9910 - val_loss: 0.1303 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.13013\n",
      "Epoch 20/100\n",
      "1750/1750 [==============================] - 404s 231ms/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.1318 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.13013\n",
      "Epoch 21/100\n",
      "1750/1750 [==============================] - 404s 231ms/step - loss: 0.0276 - acc: 0.9917 - val_loss: 0.1342 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.13013\n",
      "Epoch 22/100\n",
      "1750/1750 [==============================] - 408s 233ms/step - loss: 0.0251 - acc: 0.9923 - val_loss: 0.1336 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.13013\n",
      "Epoch 23/100\n",
      "1750/1750 [==============================] - 401s 229ms/step - loss: 0.0238 - acc: 0.9927 - val_loss: 0.1331 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.13013\n",
      "Epoch 24/100\n",
      "1750/1750 [==============================] - 402s 230ms/step - loss: 0.0242 - acc: 0.9928 - val_loss: 0.1332 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.13013\n",
      "Epoch 25/100\n",
      "1750/1750 [==============================] - 405s 231ms/step - loss: 0.0241 - acc: 0.9923 - val_loss: 0.1324 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.13013\n",
      "Epoch 26/100\n",
      "1750/1750 [==============================] - 404s 231ms/step - loss: 0.0246 - acc: 0.9927 - val_loss: 0.1326 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.13013\n",
      "Epoch 27/100\n",
      "1750/1750 [==============================] - 407s 233ms/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.1329 - val_acc: 0.9635\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13013\n",
      "Epoch 28/100\n",
      "1750/1750 [==============================] - 406s 232ms/step - loss: 0.0230 - acc: 0.9933 - val_loss: 0.1323 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13013\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-5\n",
    "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.1, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "checkpoint = ModelCheckpoint(monitor='val_loss', filepath='cifar10_F.h5', \n",
    "                             save_best_only=True, verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator.flow_from_directory('/home/crea/tf_env/train_imgs', \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                      \n",
    "                              epochs=EPOCHS, steps_per_epoch=ceil(len(x_train)/BATCH_SIZE),\n",
    "                              validation_data= test_generator.flow_from_directory('/home/crea/tf_env/valid_imgs',\n",
    "                                                                   batch_size=BATCH_SIZE),\n",
    "                              validation_steps=ceil(len(x_valid)/BATCH_SIZE),\n",
    "                              verbose=1, callbacks=[lr_reducer, early_stop, checkpoint],\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, k in enumerate(['val_acc', 'loss', 'val_loss', 'acc']):\n",
    "    with open('history_F.json', 'a') as f:\n",
    "        json.dump({k:history.history[k]}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "[0.14630968816578388, 0.9586000055074692]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7f8f700a98d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 100\n",
    "score = model.evaluate_generator(test_generator.flow_from_directory('/home/crea/tf_env/test_imgs', \n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                                  ceil(len(x_test)/BATCH_SIZE),\n",
    "                    \n",
    "                        )\n",
    "print(score)\n",
    "\n",
    "#for k in ['val_acc', 'loss', 'val_loss', 'acc']:\n",
    "#    with open('history_'+k+'.json', 'w') as f:\n",
    "#        json.dump(history.history[k], f)\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "plt.hlines(score[0], 0, len(history.history['loss']), linestyle='--', color='r')\n",
    "history_df[['acc', 'val_acc']].plot()\n",
    "plt.hlines(score[1], 0, len(history.history['acc']), linestyle='--', color='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_yolov3",
   "language": "python",
   "name": "keras_yolov3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
